(claim)#no consensus has been reached with respect to the proper methodology to use when evaluating paraphrase quality .
(claim)#this section reviews past methods for paraphrase evaluation .
(claim)#researchers usually present the quality of their automatic paraphrasing technique in terms of a subjective manual evaluation .
(claim)#these have used a variety of criteria .
0.1#(barzilay and mckeown 2001)#for example , $1 evaluated their paraphrases by asking judges whether paraphrases were " approximately conceptually equivalent . "
0.1#(ibrahim et al. 2003)#$1 asked judges whether their paraphrases were " roughly interchangeable given the genre . "
(0.1#bannard and callison burch 2005)#$1 replaced phrases with paraphrases in a number of sentences and asked judges whether the substitutions " preserved meaning and remained grammatical . "
(claim)#these subjective evaluations are rather vaguely defined and not easy to reproduce .
(claim)#others evaluate paraphrases in terms of whether they improve performance on particular tasks .
0.2#(callison burch et al. 2006b);(papineni et al., 2002)#$1 measure improvements in translation quality in terms of bleu score $2 and in terms of subjective human evaluation when paraphrases are integrated into a statistical machine translation system .
0.2#(lin and pantel 2001)#$1 manually judge whether a paraphrase might be used to answer questions from the trec question-answering track .
(claim)#to date , no one has used task-based evaluation to compare different paraphrasing methods .
(claim)#even if such an evaluation were performed , it is unclear whether the results would hold for a different task .
(claim)#because of this , we strive for a general evaluation rather than a task-specific one .
0.2#(dolan et al. 2004)#$1 create a set of manual word alignments between pairs of english sentences .
(claim)#we create a similar type of data , as described in section 4 .
0.2#(dolan et al. 2004)#$1 use heuristics to draw pairs of english sentences from a comparable corpus of newswire articles , and treat these as potential paraphrases .
(claim)#in some cases these sentence pairs are good examples of paraphrases , and in some cases they are not .
(claim)#our data differs because it is drawn from multiple translations of the same foreign sentences .
0.2#(barzilay 2003)#$1 suggested that multiple translations of the same foreign source text were a perfect source for " naturally occurring paraphrases " because they are samples of text which convey the same meaning but are produced by different writers .
0.2#(dolan et al. 2004)#that being said , it may be possible to use $1 ' data toward a similar end .
0.2#(cohn et al. to appear)#$1 compares the use of the multiple translation corpus with the msr corpus for this task .
(claim)#the work described here is similar to work in summarization evaluation .
0.2#(nenkova et al., 2007)#for example , in the pyramid method $1 content units that are similar across human-generated summaries are hand-aligned . 
(claim)#these can have alternative wordings , and are manually grouped .
(claim)#the idea of capturing these and building a resource for evaluating summaries is in the same spirit as our methodology .
