0#(gabrilovitch and markovitch 2007);(strube and ponzetto 2006);(milne et al. 2006);(zesch et al. 2007);(weale 2007)#wikipedia has been the subject of a considerable amount of research in recent years including $1 , $2 , $3 , $4 , and $5 .
0#(kazama and torisawa 2007);(toral and munoz 2006);cucerzan 2007)#the most relevant to our work are $1 , $2 , and $3 . more details follow , but it is worth noting that all known prior results are fundamentally monolingual , often developing algorithms that can be adapted to other languages pending availability of the appropriate semantic resource .
(claim)#in this paper , we emphasize the use of links between articles of different languages , specifically between english ( the largest and best linked wikipedia ) and other languages .
0#(toral and munoz 2006)#$1 used wikipedia to create lists of named entities . they used the first sentence of wikipedia articles as likely definitions of the article titles , and used them to attempt to classify the titles as people , locations , organizations , or none . unlike the method presented in this paper , their algorithm relied on wordnet ( or an equivalent resource in another language ) . the authors noted that their results would need to pass a manual supervision step before being useful for the ner task , and thus did not evaluate their results in the context of a full ner system .
0#(kazama and torisawa 2007)#similarly , $1 used wikipedia , particularly the first sentence of each article , to create lists of entities . rather than building entity dictionaries associating words and phrases to the classical ner tags ( person , location , etc . ) they used a noun phrase following forms of the verb " to be " to derive a label . for example , they used the sentence " franz fischler ... is an austrian politician " to associate the label " politician " to the surface form " franz fischler . " they proceeded to show that the dictionaries generated by their method are useful when integrated into an ner system . we note that their technique relies upon a part of speech tagger , and thus was not appropriate for inclusion as part of our non-english system .
0#(cucerzan 2007);(bunescu and pasca 2006)#$1 , by contrast to the above , used wikipedia primarily for named entity disambiguation , following the path of $2 .
0#(cucerzan 2007)#as in this paper , and unlike the above mentioned works , $1 made use of the explicit category information found within wikipedia . in particular , category and related listderived data were key pieces of information used to differentiate between various meanings of an ambiguous surface form .
0#(cucerzan 2007)#unlike in this paper , $1 did not make use of the category information to identify a given entity as a member of any particular class .
(claim)#we also note that the ner component was not the focus of the research , and was specific to the english language .
