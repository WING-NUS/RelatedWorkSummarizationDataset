(claim)#the literature on pronominal anaphora is quite large , and we cannot hope to do justice to it here .
(claim)#rather we limit ourselves to particular papers and systems that have had the greatest impact on , and similarity to , ours .
0#(cherry and bergsma 2005)#probably the closest approach to our own is $1 , which also presents an em approach to pronoun resolution , and obtains quite successful results .
(claim)#our work improves upon theirs in several dimensions .
(claim)#firstly , they do not distinguish antecedents of non-reflexive pronouns based on syntax ( for instance , subjects and objects ) .
0.1#(tetreault 2001)#both previous work ( cf . $1 discussed below ) and our present results find these distinctions extremely helpful . secondly , their system relies on a separate preprocessing stage to classify non-anaphoric pronouns , and mark the gender of certain nps ( mr. , mrs. and some first names ) . this allows the incorporation of external data and learning systems , but conversely , it requires these decisions to be made sequentially . our system classifies non-anaphoric pronouns jointly , and learns gender without an external database . next , they only handle third-person pronouns , while we handle first and second as well . finally , as a demonstration of em 's capabilities , its evidence is equivocal . their em requires careful initialization sufficiently careful that the em version only performs 0.4 % better than the initialized program alone .
(claim)#( we can say nothing about relative performance of their system vs. ours since we have been able to access neither their data nor code . )
0.2#(kehler et al. 2004a);(haghighi and klein, 2007)#a quite different unsupervised approach is $1 , which uses self-training of a discriminative system , initialized with some conservative number and gender heuristics . the system uses the conventional ranking approach , applying a maximum-entropy classifier to pairs of pronoun and potential antecedent and selecting the best antecedent . in each iteration of self-training , the system labels the training corpus and its decisions are treated as input for the next training phase . the system improves substantially over a hobbs baseline . in comparison to ours , their feature set is quite similar , while their learning approach is rather different . in addition , their system does not classify non-anaphoric pronouns , a third paper that has significantly influenced our work is that of $2 .
(claim)#this is the first paper to treat all noun phrase ( np ) anaphora using a generative model .
(claim)#the success they achieve directly inspired our work .
(claim)#there are , however , many differences between their approach and ours .
(claim)#the most obvious is our use of em rather than theirs of gibbs sampling .
(claim)#however , the most important difference is the choice of training data .
(claim)#in our case it is a very large corpus of parsed , but otherwise unannotated text .
(claim)#their system is trained on the ace corpus , and requires explicit annotation of all markable things that are or have antecedents .
(claim)#for pronouns , only anaphoric pronouns are so marked .
(claim)#thus the system does not learn to recognize non-anaphoric pronouns a significant problem .
(claim)#more generally it follows from this that the system only works ( or at least works with the accuracy they achieve ) when the input data is so marked .
(claim)#these markings not only render the non-anaphoric pronoun situation moot , but also significantly restrict the choice of possible antecedent .
0.2#(poesio and vieira, 1998)#only perhaps one in four or five nps are markable $1 .
0.2#(cardie and wagstaff, 1999);(angheluta et al., 2004)#there are also several papers which treat coference as an unsupervised clustering problem $1 $2 .
(claim)#in this literature there is no generative model at all , and thus this work is only loosely connected to the above models .
0.2#(ge et al., 1998)#another key paper is $1 . the data annotated for the ge research is used here for testing and development data . also , there are many overlaps between their formulation of the problem and ours . for one thing , their model is generative , although they do not note this fact , and ( with the partial exception we are about to mention ) they obtain their probabilities from hand annotated data rather than using em . lastly , they learn their gender information ( the probability of that a pronoun will have a particular gender given its antecedent ) using a truncated em procedure . once they have derived all of the other parameters from the training data , they go through a larger corpus of unlabeled data collecting estimated counts of how often each word generates a pronoun of a particular gender . they then normalize these probabilities and the result is used in the final program . this is , in fact , a single iteration of em .
0.2#(tetreault 2001);(ge et al., 1998)#$1 is one of the few papers that use the $2 corpus used here . they achieve a very high 80 % correct , but this is given hand-annotated number , gender and syntactic binding features to filter candidate antecedents and also ignores non-anaphoric pronouns .
(claim)#we defer discussion of the systems against which we were able to compare to section 7 on evaluation .
